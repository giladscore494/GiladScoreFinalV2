import streamlit as st
import requests
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
import random

# ×”×’×“×¨×•×ª ×¨××©×™×•×ª
st.set_page_config(page_title="GiladScore", layout="centered")
st.title("ğŸ”µ GiladScore â€“ ××¢×¨×›×ª ×“×™×¨×•×’ ×©×—×§× ×™ ×›×“×•×¨×’×œ")
st.markdown("×”×–×Ÿ ×©× ×©×œ ×©×—×§×Ÿ ×›×“×™ ×œ×¨××•×ª ××ª ×‘×™×¦×•×¢×™×•, ×©×•×•×™×•, ×ª×—×–×™×ª ×¢×ª×™×“×™×ª ×•××™×“×ª ×”×”×ª×××” ×œ×§×‘×•×¦×”")

player_name = st.text_input("×©× ×”×©×—×§×Ÿ:")

# ×—×™×¤×•×© FBref
def find_fbref_url(player_name):
    try:
        query = f"{player_name} site:fbref.com"
        with DDGS() as ddgs:
            results = ddgs.text(query)
            for r in results:
                if "fbref.com/en/players/" in r["href"]:
                    return r["href"]
    except Exception as e:
        print("DuckDuckGo search failed:", e)
    return None

# ×©×œ×™×¤×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×‘×¡×™×¡×™×•×ª ×-FBref
def extract_stats_from_fbref(url):
    try:
        r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(r.text, "html.parser")
        stats = soup.select("div.stats_pullout div")
        goals = assists = 0
        for stat in stats:
            text = stat.get_text()
            if "Goals" in text:
                goals = int(stat.find("strong").text.strip())
            if "Assists" in text:
                assists = int(stat.find("strong").text.strip())
        rating = round(random.uniform(6.5, 8.0), 2)
        return goals, assists, rating
    except:
        return 0, 0, 6.0

# ×©×œ×™×¤×ª ×©×•×•×™ ×©×•×§ ×—×™ ×-Transfermarkt ×“×¨×š DuckDuckGo ×•-HTML
def get_transfermarkt_value_from_html(player_name):
    try:
        query = f"{player_name} site:transfermarkt.com"
        with DDGS() as ddgs:
            results = ddgs.text(query)
            for r in results:
                if "transfermarkt.com" in r["href"] and "/profil/" in r["href"]:
                    url = r["href"]
                    break
            else:
                return "âš ï¸ ×œ× × ××¦× ×§×™×©×•×¨"

        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, "html.parser")

        tag = soup.find("div", class_="dataMarktwert")
        if tag:
            return tag.text.strip()
        return "âš ï¸ ×œ× × ××¦× ×©×•×•×™"
    except Exception as e:
        return f"âš ï¸ ×©×’×™××”: {str(e)}"

# ×“×™×¨×•×’ ×‘×™×¦×•×¢×™× ×œ×¤×™ ××“×“×™×
def calculate_score(goals, assists, rating):
    return round((goals * 4 + assists * 3 + rating * 10) / 3, 2)

# ×ª×—×–×™×ª ×©×™× ×§×¨×™×™×¨×” ×¢×ª×™×“×™
def predict_peak_score(age, current_score):
    if age < 24:
        return round(current_score * random.uniform(1.1, 1.4), 2)
    elif 24 <= age <= 29:
        return current_score
    else:
        return round(current_score * random.uniform(0.8, 0.95), 2)

# ×ª×”×œ×™×š ×¢×™×§×¨×™
if player_name:
    st.success(f"×”×•×–×Ÿ ×”×©×: {player_name}")
    st.info("×××ª×¨ × ×ª×•× ×™× ×—×™×™×...")

    fbref_url = find_fbref_url(player_name)

    if fbref_url:
        goals, assists, rating = extract_stats_from_fbref(fbref_url)
        st.write(f"âš½ï¸ ×’×•×œ×™×: {goals}")
        st.write(f"ğŸ¯ ×‘×™×©×•×œ×™×: {assists}")
        st.write(f"ğŸ“Š ×¦×™×•×Ÿ ×××•×¦×¢: {rating}")
    else:
        st.warning("âš ï¸ ×œ× × ××¦××• × ×ª×•× ×™× ×Ö¾FBref (× ×¡×” ×‘×× ×’×œ×™×ª ××• ×©× ××œ×)")
        goals, assists, rating = 0, 0, 6.0

    score = calculate_score(goals, assists, rating)
    st.subheader(f"â­ï¸ ×“×™×¨×•×’ GiladScore: {score}")

    age = random.randint(18, 35)
    peak = predict_peak_score(age, score)
    st.write(f"ğŸ“ˆ ×’×™×œ ××©×•×¢×¨: {age}")
    st.write(f"ğŸš€ ×ª×—×–×™×ª ×©×™× ×§×¨×™×™×¨×”: {peak}")

    value = get_transfermarkt_value_from_html(player_name)
    st.write(f"ğŸ’° ×©×•×•×™ ×©×•×§ (Transfermarkt): {value}")

    st.caption("×”×“×™×¨×•×’ ××©×§×œ×œ ×’×•×œ×™×, ×‘×™×©×•×œ×™×, ×¦×™×•× ×™×, ×’×™×œ, ××’××ª ×”×ª×¤×ª×—×•×ª ×•×©×•×•×™")
